{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute Force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily make new \"Bedroom Heuristics\" simply by changing the amount of dollars we multiply the number of bedrooms by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import evaluate_model\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def generate_bedroom_heuristic(a):\n",
    "    def heuristic(input_data):\n",
    "        prediction = a * input_data['BedroomAbvGr']\n",
    "        return(prediction)\n",
    "    return(heuristic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question is now \"What's the best amount of dollars to multiply by?\" \n",
    "\n",
    "Let's start to answer this by using a for loop and trial and error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = []\n",
    "for i in range(200):\n",
    "    score = evaluate_model(generate_bedroom_heuristic(i*1000))\n",
    "    model_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_scores)\n",
    "plt.xlabel(\"Bedrooms x 1000\")\n",
    "plt.ylabel(\"Mean absolute error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum score.\n",
    "models = pd.DataFrame()\n",
    "models['Score'] = model_scores\n",
    "models.loc[models.Score == models.Score.min()] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One issue with this approach is choosing an appropriate level of granularity. In this example we stepped through increments of 1000. But how do we know the optimal value really is \\$54,000 and not \\$53,765.08 ? We could lower our step size but this would mean increasing our compute time by orders of magnitude. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermezzo: Optimisation\n",
    "\n",
    "The science of doing the above effectively is called optimisation. There are some brilliant algorithms for doing optimisation, the most popular in machine learning is called minibatch gradient descent. You can see an outline of this algorithm [here.](https://cs.brown.edu/courses/csci1951-a/assignments/regression.html)\n",
    "\n",
    "The idea behind the algorithm is to use calculus. As you may recall from high school maths, when the gradient $dy/dx  = 0$  then y is at a minimum or maximimum. This is illustrated in the following diagram.\n",
    "\n",
    "<img src=\"https://cs.brown.edu/courses/csci1951-a/assignments/images/gd.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "Rather than brute force this, we can use a library.\n",
    "\n",
    "First, let's define our problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Problem*\n",
    "\n",
    "Find $w_0, w_1$ such that $w_1 \\cdot bedrooms + w_0$ gives the most accurate predictions (as measured by mean absolute error.)\n",
    "\n",
    "\n",
    "This is a problem of model fitting, not model evaluation, so we use the train data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bedroom_linear_model(training_set):\n",
    "    predictor = linear_model.LinearRegression()\n",
    "    predictor.fit(training_set[['BedroomAbvGr']],training_set['SalePrice'])\n",
    "    def bedroom_linear_model(input_data):\n",
    "        return(predictor.predict(input_data[['BedroomAbvGr']]))\n",
    "    return bedroom_linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv(\"housing_price_data/training_data.csv\")\n",
    "bedroom_linear_model = train_bedroom_linear_model(training_set)\n",
    "evaluate_model(bedroom_linear_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the differences between predicted and actual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedroom_example = training_set.copy()\n",
    "bedroom_example['Predicted'] = bedroom_linear_model(bedroom_example)\n",
    "bedroom_example['Error'] = bedroom_example['Predicted'] - bedroom_example['SalePrice']\n",
    "bedroom_example['Error'].plot()  #TODO label axes.\n",
    "plt.xlabel(\"id\")\n",
    "plt.ylabel(\"Difference between predictive and actual value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the outliers by sorting the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedroom_example.sort_values(\"Error\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Why do you think the outliers are so cheap? Remember you can look at individual columns by using\n",
    "`bedroom_example[[\"column1\",\"column2\",...]]`\n",
    "\n",
    "Exercise: Build a linear regression model for predicting SalePrice as a function of LotArea"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
