{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "In the last lab we manually figured out the multiplier that minimises the error, but this is a machine learning course! In this lab we'lllet the machine figure out a model.\n",
    "\n",
    "Linear regression is one of the simplest machine learning models, and attempts to do what we just manually performed - fit a line to a set of input features. In addition to our previous manual model, however, it also allows the following:\n",
    "\n",
    "- Includes a bias (the $+ c$ part of $y=mx + c$).\n",
    "- Allows an arbitrary number of input features. e.g. if you had 2 features $x_1$ and $x_2$, the model equation could be written as: $y = w_1 x_1 + w_2 x_2 + c$\n",
    "- Automatically calculates the weights to minimise the Residual Sum of Squares.\n",
    "\n",
    "In the code below we make use of the the Scitkit-Learn library that provides us with functions to create and train a model. \n",
    "\n",
    "Use the [Scikit-Learn Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Scikit_Learn_Cheat_Sheet_Python.pdf) to help you understand the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**\n",
    "- sklearn.linear_model.LinearRegression\n",
    "- .fit and .predict to use\n",
    "- .coef_ and .intercept_ to get information on the resulting model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, load the data\n",
    "\n",
    "As with the last lab, we'll load and split our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_housing_data(test_size=0.2, random_state=2020):\n",
    "    # Load data from Eliiza's github page\n",
    "    raw_data = pd.read_csv(\"https://raw.githubusercontent.com/eliiza/ml-training-data/master/housing_price_data/housing_data.csv\") \n",
    "\n",
    "    # Separate labels from feature columns.\n",
    "    X = raw_data.drop('SalePrice', axis=1)\n",
    "    y = raw_data['SalePrice']\n",
    "    \n",
    "    # Split the dataset with the requested proportions.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Return in standard order.\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "selected_columns = ['OverallQual']\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Fit the model on the selected columns\n",
    "lin_reg.fit(X_train[selected_columns], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And test it\n",
    "\n",
    "Thats it! We've built a simple model, now we can start making predictions using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = lin_reg.predict(X_test[selected_columns])\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the model parameters\n",
    "\n",
    "It is possible to inspect the model parameters, in this case the co-efficients and bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Multiplier:\", lin_reg.coef_)\n",
    "print(\"Bias:\", lin_reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have time, try plugging these numbers in to the simple predictor we made in the previous lab - remember to add in a bias parameter though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "### Exercise \n",
    "\n",
    "Look back at the correlation matrix from the previous lab and try using other columns for the linear regression model.\n",
    "\n",
    "- Do you get more accurate results?\n",
    "- How many `.coef_` coefficients are there in the new model? Why?\n",
    "- Does the model take longer to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An introduction to input pipelines\n",
    "\n",
    "When training and testing our models, we want to have a consistent input pipeline to ensure the data is sanitised correctly.\n",
    "\n",
    "In this case we'll use a very simple pipeline that will provide a starting point to expand in future notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "selected_columns = ['OverallQual', 'BedroomAbvGr']\n",
    "\n",
    "simple_pipeline = ColumnTransformer([('column filter', 'passthrough', selected_columns)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to fit both the pipeline and the model. In this case, the pipeline doesn't apply any computations so fitting it doesn't actually do anything. In future notebooks this will change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pre-process input data. Include fit to configure any parameters in the pipeline.\n",
    "X_train_prepared = simple_pipeline.fit_transform(X_train)\n",
    "\n",
    "# Train Linear Regression model.\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input pipeline has been configured, and our model has been trained. Now we can try them out and evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When testing, we don't want to fit the pipeline, only apply the transformations\n",
    "X_test_prepared = simple_pipeline.transform(X_test)\n",
    "\n",
    "y_pred = lin_reg.predict(X_test_prepared)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
