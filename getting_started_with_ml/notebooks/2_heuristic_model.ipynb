{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "# Simple ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the following data science libraries throughout this course (click the links for cheat sheets provided by DataCamp)\n",
    "* [numpy](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf)  (for vectorised math operations)\n",
    "* [pandas](https://datacamp-community-prod.s3.amazonaws.com/9f0f2ae1-8bd8-4302-a67b-e17f3059d9e8) (for dataframes)\n",
    "* [keras](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Keras_Cheat_Sheet_Python.pdf) (for neural networks)\n",
    "* [scikitlearn](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Scikit_Learn_Cheat_Sheet_Python.pdf) (for other machine learning models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "The first step to training models is to figure out a way to tell how good a model is.  \n",
    "\n",
    "You can't just train until it \"gets the right results\", there will almost always be some difference between the predicted outcome and the measured outcomes.\n",
    "\n",
    "To tackle this, we'll split our data up into a \"training set\" (for inspection and training models), and a \"test set\" for model evaluation.\n",
    "\n",
    "This is to ensure a fair test of the model's ability to generalise to new examples. The same reason why an exam contains different questions to the practice exams a student learns from.\n",
    "\n",
    "Throughout this module, we'll be using the [Ames Housing Prices Data Set](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)\n",
    "\n",
    "The data is described [here](https://github.com/eliiza/ml-training-data/blob/master/housing_price_data/data_description.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intro to sklearn\n",
    "- After wrangling with Pandas -> machine learning library\n",
    "- Huge advantage in consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching the data\n",
    "\n",
    "We'll start by making a function that allows us to fetch the dataset and split it into a test and training set. The funciton will allow you to:\n",
    "\n",
    "- Choose the percentage split between training and test data.\n",
    "- Seed the random number generator to split the data the same way each run-through."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sklearn function:** [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_housing_data(test_size=0.2, random_state=2020):\n",
    "    # Load data from Eliiza's github page\n",
    "    raw_data = pd.read_csv(\"https://raw.githubusercontent.com/eliiza/ml-training-data/master/housing_price_data/housing_data.csv\") \n",
    "\n",
    "    # Separate labels from feature columns.\n",
    "    X = raw_data.drop('SalePrice', axis=1)\n",
    "    y = raw_data['SalePrice']\n",
    "    \n",
    "    # Split the dataset with the requested proportions.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Return in standard order.\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- How many observations are in the training and test datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Performance Measure\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Absolute Error\n",
    "\n",
    "Now that we have a test set, we can start to evaluate some models!\n",
    "\n",
    "We'll use the mean absolute error. This is the average size of the difference between the predicted value vs the observed value.\n",
    "\n",
    "Formally, this is defined as\n",
    "\n",
    "$$  \\mathsf{MAE} = \\frac{1}{n} * \\sum_{i=1}^n |\\mathsf{predicted\\_value}[i] - \\mathsf{actual\\_value}[i]|  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good to understand how MAE is calculated, but SciKit Learn provides functions to calculate it for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "# A heuristic model\n",
    "\n",
    "You will  most likely be familiar with the equation $y = mx + c$. We are going to go one step simpler. In this section we will pick a single column, which will be our $x$, and attempt to manually fit the gradient $m$, which we will call the multiplier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_predictor(X, target_column='OverallQual', multiplier=50000):\n",
    "    return multiplier * X[target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the training and test data.\n",
    "(X_train, y_train), (X_test, y_test) = load_housing_data(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions on the test dataset.\n",
    "y_pred = simple_predictor(X_test, multiplier=50000)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Try some different values of the multiplier and see if you can find an optimal value. What techniques can you use to improve your guessing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to improve your guesses is to slightly adjust the multiplier up and down, determine which direction makes the error smaller and try a new guess in that direction.\n",
    "\n",
    "Another way is to plot the error across a range of multipliers, then estimate the best value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "multipliers = []\n",
    "\n",
    "for i in range(1000,60000,1000):\n",
    "    y_pred = simple_predictor(X_train, multiplier=i)\n",
    "\n",
    "    mae = mean_absolute_error(y_train, y_pred)\n",
    "    \n",
    "    errors.append(mae)\n",
    "    multipliers.append(i)\n",
    "    \n",
    "plt.plot(multipliers, errors)\n",
    "plt.xlabel('Multiplier')\n",
    "plt.ylabel('Mean Abs. Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Based on the above graph, what is the best choice of multiplier? Are you able to get a MAE below $40,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
