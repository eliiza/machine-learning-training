{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Neural Networks\n",
    "\n",
    "In this notebook we will use the same dataset and pre-processing as the previous notebook, but build a simple Neural Network and go into more detail about how it works and how we might change the structure.\n",
    "\n",
    "But first, we'll reload the dataset and import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# Reshape the labels.\n",
    "train_labels = train_labels[:,0]\n",
    "test_labels = test_labels[:,0]\n",
    "\n",
    "# And scale.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Index to name mapping.\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train a simple neural network\n",
    "\n",
    "Start building and training the network, then as it is going we'll discuss what is actually going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 3)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is going on?\n",
    "\n",
    "A typical structure is an input layer, a number of hidden layers, and an output layer.\n",
    "\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(32, 32, 3)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "So what is each layer doing?\n",
    "\n",
    "#### Flatten\n",
    "\n",
    "The input images are `32 x 32 x 3`, our simple network is expecting a one dimensional array of inputs, this layer simply flattens the input to a 1D array.\n",
    "\n",
    "#### Dense Layer 1\n",
    "\n",
    "The first dense layer comprised 128 neurons, with each neuron connected with a weighted link to each of the inputs. The output of each neuron is calculated by summing the weights of the inputs, then applying the ReLU activation function to the sum.\n",
    "\n",
    "#### Dense Layer 2\n",
    "\n",
    "This is the final layer! As you'll remember there are 10 categories that we are trying to classify, and this layer has a neuron to represent each one. Ideally when an image of a truck is fed into the network, the \"truck\" neuron will output a very high value while the others will be very low. The softmax activation normalises the outputs to total one and give a relative confidence of each category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty poor performance...but given it only took a couple of minutes to build it is quite impressive.\n",
    "\n",
    "As mentioned, the final layer of the network has 10 neurons, with a softmax activation. What this means is that it will provide 10 outputs, each representing a measure of how confident the network is that an image belongs to a particular category. (The softmax makes these outputs add to 1 to show relative confidence between the outputs.)\n",
    "\n",
    "Lets step through some predictions to understand this in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(np.array([test_images[0]]))\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are 10 floating point numbers giving a relative confidence of each of the 10 categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "Calculate the sum of the prediction array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which index has the highest value? And what category does that correspond to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** Try replacing the \"softmax\" activation with a \"relu\" one, what happens to the outputs? Is that what you expected? Do they still give category predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the output\n",
    "\n",
    "Now we'll look at the performance on a group of images. Red bars indicate an incorrect prediction, blue bars represent the correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#\n",
    "# Don't spend too much time understanding this - it is used to make pretty plots.\n",
    "#\n",
    "###\n",
    "\n",
    "def plot_image_predictions(img, predictions, true_label, class_names):\n",
    "  plt.figure(figsize=(6, 3))\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plot_image(img, predictions, true_label, class_names)\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plot_value_array(predictions, true_label, class_names)\n",
    "  plt.show()\n",
    "\n",
    "def plot_image(img, predictions, true_label, class_names):\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions)\n",
    "\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(predictions, true_label, class_names):\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot(index):\n",
    "    pred = model.predict(np.array([test_images[index]]))\n",
    "    plot_image_predictions(test_images[index], pred[0], test_labels[index], class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    predict_and_plot(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try adding an extra dense layer\n",
    "\n",
    "As a sample exercies, lets add some more layers to the neural network from the previous notebook and see how it preforms.\n",
    "\n",
    "Other improvements could be adjusting the learning rate, activation functions, or more advanced features like dropout, image augmentation, convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an extra layer somewhere here:\n",
    "deep_model = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 3)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same optimizer/loss/metrics\n",
    "deep_model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = deep_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "How many parameters require training in the new model? (try plotting the model summary...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other questions:\n",
    "* What was the impact on training time?\n",
    "* How much did accuracy improve?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
