{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do the different models compare?\n",
    "\n",
    "We will compare the model evaluation results across the models we've trained in this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import sklearn.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use same evaluate_model function as before\n",
    "def evaluate_model(model_fn, print_result=False):\n",
    "    '''\n",
    "    Consumes a function model_fn\n",
    "    and evaluates its predictive accuracy against \n",
    "    the housing prices test set.\n",
    "    We have included a switch for the output to be a more human readable\n",
    "    printed version or the uncurtailed floating point value of the average.\n",
    "    '''\n",
    "    test_data = pd.read_csv(\"https://raw.githubusercontent.com/eliiza/ml-training-data/master/housing_price_data/test_data.csv\")\n",
    "    actual_values = test_data['SalePrice']\n",
    "    # Pass in all columns except SalePrice\n",
    "    test_input = test_data.filter(regex='^(?!SalePrice$).*')\n",
    "    predicted_saleprice = model_fn(test_input)\n",
    "    mae = np.mean(np.abs(predicted_saleprice-actual_values))\n",
    "    if print_result:\n",
    "        return print(\"The model is inaccurate by $%.2f on average.\" % mae)\n",
    "    else:\n",
    "        return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for data encoding\n",
    "\n",
    "# Step 1: Feature Engineering\n",
    "def encode_data(data,scaler = None):\n",
    "    \"\"\"\n",
    "    Encode a dataframe of house price data using the desired feature engineering process. \n",
    "    The scaler argument allows you to either scale the data anew (scaler = None), \n",
    "    or use previously derived scaling parameters\n",
    "    e.g. when you want to encoding test data using the scaling parameters from the training dataset.\n",
    "    Returns a dataframe of engineered features and the scaler object.\n",
    "    \"\"\"\n",
    "    \n",
    "    features = data.copy()\n",
    "    \n",
    "    # Numerical features\n",
    "    features = features[['OverallQual','GrLivArea','BedroomAbvGr','FullBath','YearBuilt']]\n",
    "    features['QualAreaInteract'] = features['OverallQual'] * features['GrLivArea']\n",
    "    \n",
    "    # Ordinal feature - map to numerical as before\n",
    "    cond_map = {'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1}\n",
    "    features['KitchenQual'] = data['KitchenQual'].map(cond_map).fillna(0)\n",
    "    \n",
    "    # Categorical features - one-hot encode using pre-written helper functions (below)\n",
    "    features['CentralAir'] = data['CentralAir'] == 'Y'\n",
    "    electrical = encode_electrical(data['Electrical'])\n",
    "    heating = encode_heating(data['Heating'])\n",
    "    features = pd.concat([features,electrical,heating],axis=1)\n",
    "    \n",
    "    # Convert to float data type for scaling process\n",
    "    features = features.astype(float)\n",
    "    \n",
    "    # Scale all the features\n",
    "    # If no `scaler` object in the function arguments - carry out scaling anew\n",
    "    # If `scaler` object in the function arguments - use those scaling parameters\n",
    "    if(not scaler):\n",
    "       scaler = MinMaxScaler()\n",
    "       scaler.fit(features)\n",
    "    features = pd.DataFrame(scaler.transform(features), \n",
    "                            columns = ['OverallQual','GrLivArea','BedroomAbvGr','FullBath','YearBuilt',\n",
    "                                       'QualAreaInteract','KitchenQual',\n",
    "                                       'CentralAir','FuseA','FuseF','FuseP','Mix','SBrkr',\n",
    "                                       'GasA','GasW','Grav','Wall'])\n",
    "    \n",
    "    # Return the desired data frame and the scaling parameters used\n",
    "    return(features,scaler)\n",
    "\n",
    "\n",
    "# Helper functions for one hot encoding\n",
    "\n",
    "def encode_electrical(electrical):\n",
    "    \"\"\"\n",
    "    Create data frame with one column per category in 'electrical' column, rows are Boolean with respect to\n",
    "    category string in electrical column.\n",
    "    \"\"\"\n",
    "    one_hot_encoding = pd.DataFrame()\n",
    "    one_hot_encoding['FuseA'] = electrical == 'FuseA'\n",
    "    one_hot_encoding['FuseF'] = electrical == 'FuseF'\n",
    "    one_hot_encoding['FuseP'] = electrical == 'FuseP'\n",
    "    one_hot_encoding['Mix']   = electrical == 'Mix'\n",
    "    one_hot_encoding['SBrkr'] = electrical == 'SBrkr'\n",
    "    return(one_hot_encoding)\n",
    "\n",
    "def encode_heating(heating):\n",
    "    \"\"\"\n",
    "    Create data frame with one column per category in 'heating' column, rows are Boolean with respect to\n",
    "    category string in heating column.\n",
    "    \"\"\"\n",
    "    one_hot_encoding = pd.DataFrame()\n",
    "    one_hot_encoding['GasA'] = heating == 'GasA'\n",
    "    one_hot_encoding['GasW'] = heating == 'GasW'\n",
    "    one_hot_encoding['Grav'] = heating == 'Grav'\n",
    "    one_hot_encoding['Wall'] = heating == 'Wall'\n",
    "    return(one_hot_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv(\"https://raw.githubusercontent.com/eliiza/ml-training-data/master/housing_price_data/training_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic Brute Force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(input_data):\n",
    "    \"\"\"\n",
    "    Extracts a single vector called 'OverallQual' from input data and multiplies every value by 100,000\n",
    "    \"\"\"\n",
    "    bedrooms = input_data['OverallQual']\n",
    "    prediction = 29000*bedrooms\n",
    "    return(prediction)\n",
    "\n",
    "brute_force = evaluate_model(heuristic, print_result=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = training_set[['OverallQual']]\n",
    "predictor = linear_model.LinearRegression()\n",
    "predictor.fit(training_features, training_set['SalePrice'])\n",
    "\n",
    "# Define function with prediction\n",
    "def linear_model(input_data):\n",
    "    return(predictor.predict(input_data[['OverallQual']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg = evaluate_model(linear_model, print_result=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Feature engineering\n",
    "training_features, scaler = encode_data(training_set)\n",
    "    \n",
    "# Step 2: Train the model\n",
    "predictor = sklearn.linear_model.LinearRegression()\n",
    "predictor.fit(training_features, training_set['SalePrice'])\n",
    "\n",
    "# Step 3: Create a function that can make predictions using the model\n",
    "def mlr_model(input_data):\n",
    "    input_features,_ = encode_data(input_data,scaler)\n",
    "    predictions = predictor.predict(input_features)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Evaluate\n",
    "mlr = evaluate_model(mlr_model, print_result=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Feature engineering\n",
    "training_features, scaler = encode_data(training_set)\n",
    "\n",
    "# Step 2: Train the model\n",
    "predictor = sklearn.ensemble.RandomForestRegressor(n_estimators=100) \n",
    "predictor.fit(training_features, training_set['SalePrice'])\n",
    "\n",
    "# Step 3: Create a function that can make predictions using the model\n",
    "def rf_model(input_data):\n",
    "    input_features,_ = encode_data(input_data,scaler)\n",
    "    predictions = predictor.predict(input_features)\n",
    "    return(predictions)\n",
    "\n",
    "# Step 4: Evaluate\n",
    "rf = evaluate_model(rf_model, print_result=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Feature engineering\n",
    "training_features, scaler = encode_data(training_set)\n",
    "\n",
    "# Step 2: Train the model\n",
    "predictor = sklearn.ensemble.GradientBoostingRegressor()\n",
    "predictor.fit(training_features, training_set['SalePrice'])\n",
    "\n",
    "# Step 3: Create a function that can make predictions using the model\n",
    "def boosting_model(input_data):\n",
    "    input_features,_ = encode_data(input_data,scaler)\n",
    "    predictions = predictor.predict(input_features)\n",
    "    return(predictions)\n",
    "\n",
    "# Step 4: Evaluate\n",
    "gb = evaluate_model(boosting_model, print_result=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'Mean Absolute Error $':[brute_force, linear_reg, mlr, rf, gb],\n",
    "                        'Model': ['Brute Force', 'Linear Regression', 'Multiple Linear Regression', \n",
    "              'Random Forest', 'Gradient Boosting']})\n",
    "results = results.sort_values('Mean Absolute Error $')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = results.plot.barh(x='Model', y='Mean Absolute Error $', rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ax.get_figure()\n",
    "fig.savefig('./model_comparison.png', dpi = 300, bbox_inches= 'tight', pad_inches = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
